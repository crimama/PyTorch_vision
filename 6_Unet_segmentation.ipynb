{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet을 이용한 Image Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레퍼런스 : https://colab.research.google.com/github/dhrim/MDC_2021/blob/master/material/deep_learning/unet_segmentation_multi_label.ipynb#scrollTo=cHnifLferK9Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.datasets import VOCSegmentation\n",
    "\n",
    "# a = VOCSegmentation(root='./data',year='2012',image_set='train',download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Pytorch_vision/data\n"
     ]
    }
   ],
   "source": [
    "%cd '/data/Pytorch_vision/data'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "from glob import glob\n",
    "import cv2  \n",
    "#데이터 로드 \n",
    "%cd '/data/Pytorch_vision/data'\n",
    "def data_dir_load():\n",
    "    label_dirs = sorted(glob('VOCdevkit/VOC2012/SegmentationClass/*.png'))\n",
    "    img_dirs = sorted(glob('VOCdevkit/VOC2012/JPEGImages/*.jpg'))[:len(label_dirs)]\n",
    "    return img_dirs ,label_dirs \n",
    "\n",
    "class divide(nn.Module):\n",
    "    def __init__(self,divide_value):\n",
    "        super().__init__()\n",
    "        self.divide_value = divide_value\n",
    "\n",
    "    def forward(self,img):\n",
    "        return img/self.divide_value\n",
    "\n",
    "def image_transform():\n",
    "    transform = transforms.Compose([\n",
    "        divide(255),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.Normalize(mean=0.5,std=0.5)\n",
    "    ])\n",
    "    return transform \n",
    "\n",
    "class Dset(Dataset):\n",
    "    def __init__(self,image_dirs,label_dirs,transform):\n",
    "        super().__init__()\n",
    "        self.image_dirs = image_dirs \n",
    "        self.label_dirs = label_dirs \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_dirs)\n",
    "\n",
    "    def image_transform(self,img):\n",
    "        return self.transform(img)\n",
    "\n",
    "    def image_label_load(self,img_dir,label_dir):\n",
    "        img = cv2.imread(img_dir)\n",
    "        label = cv2.imread(label_dir)\n",
    "        return img,label\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        self.idx = idx \n",
    "        img,label = self.image_label_load(self.image_dirs[idx],self.label_dirs[idx])\n",
    "\n",
    "        self.image = self.image_transform(img)\n",
    "        self.label = self.image_transform(label)\n",
    "\n",
    "        return self.image, self.label \n",
    "\n",
    "def train_valid_split(images,labels):\n",
    "    length = len(images)\n",
    "    split_index = int(length*0.8)\n",
    "    train_images,test_images = images[:split_index], images[split_index:]\n",
    "    train_labels,test_labels = labels[:split_index], labels[split_index:]\n",
    "    return train_images,test_images,train_labels,test_labels \n",
    "\n",
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self,input_c,output_c):\n",
    "        super().__init__()\n",
    "        self.conv_in = nn.Conv2d(in_channels=input_c,out_channels=output_c,kernel_size=3,padding=1)\n",
    "        self.conv = nn.Conv2d(in_channels=output_c,out_channels=output_c,kernel_size=3,padding=1)\n",
    "        self.batchnorm = nn.BatchNorm2d(output_c)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_in(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        conv = self.batchnorm(x)\n",
    "        pool = self.maxpool(conv)\n",
    "        return conv,pool\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv_Block(3,32)\n",
    "        self.conv2 = Conv_Block(32,64)\n",
    "        self.conv3 = Conv_Block(64,128)\n",
    "        self.conv4 = Conv_Block(128,256)\n",
    "        self.conv5 = self.Conv_last(256,512)\n",
    "\n",
    "    def Conv_last(self,input_c,output_c):\n",
    "        block = nn.Sequential(\n",
    "                                nn.Conv2d(input_c,output_c,3,padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(output_c),\n",
    "                                nn.Conv2d(output_c,output_c,3,padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(output_c)\n",
    "        )\n",
    "        return block \n",
    "\n",
    "    def forward(self,x):\n",
    "        conv1,pool1 = self.conv1(x)\n",
    "        conv2,pool2 = self.conv2(pool1)\n",
    "        conv3,pool3 = self.conv3(pool2)\n",
    "        conv4,pool4 = self.conv4(pool3)\n",
    "        conv5 = self.conv5(pool4)\n",
    "        return conv1,conv2,conv3,conv4,conv5\n",
    "\n",
    "class Conv_up_block(nn.Module):\n",
    "    def __init__(self,input_c,output_c):\n",
    "        super().__init__()\n",
    "        self.up_sample = nn.ConvTranspose2d(input_c,output_c,2,stride=2,padding=0)\n",
    "        self.conv1 = nn.Conv2d(input_c,output_c,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(output_c,output_c,3,padding=1)\n",
    "        self.batchnorm = nn.BatchNorm2d(output_c)\n",
    "\n",
    "\n",
    "    def forward(self,x,conv):\n",
    "        self.up = self.up_sample(x)\n",
    "        x = torch.cat((self.up,conv),dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batchnorm(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batchnorm(x)\n",
    "        \n",
    "        return x \n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_up1 = Conv_up_block(512,256)\n",
    "        self.conv_up2 = Conv_up_block(256,128)\n",
    "        self.conv_up3 = Conv_up_block(128,64)\n",
    "        self.conv_up4 = Conv_up_block(64,32)\n",
    "        self.conv_last = nn.Conv2d(32,3,1,padding=0)\n",
    "    \n",
    "    def forward(self,conv1,conv2,conv3,conv4,conv5):\n",
    "        up = self.conv_up1(conv5,conv4)\n",
    "        up = self.conv_up2(up,conv3)\n",
    "        up = self.conv_up3(up,conv2)\n",
    "        up = self.conv_up4(up,conv1)\n",
    "        up = self.conv_last(up)\n",
    "        up = F.softmax(up,dim=1)\n",
    "        return up \n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Down = Down()\n",
    "        self.Up = Up()\n",
    "\n",
    "    def forward(self,x):\n",
    "        conv1,conv2,conv3,conv4,conv5 = self.Down(x)\n",
    "        x = self.Up(conv1,conv2,conv3,conv4,conv5)\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    batch_size = 2\n",
    "    epoch = 50\n",
    "\n",
    "img_dirs,label_dirs = data_dir_load() \n",
    "train_img_dirs,test_img_dirs,train_label_dirs,test_label_dirs = train_valid_split(img_dirs,label_dirs)\n",
    "\n",
    "image_transformer = image_transform()\n",
    "train_dataset = Dset(train_img_dirs, train_label_dirs,image_transformer)\n",
    "test_dataset = Dset(test_img_dirs,test_label_dirs,image_transformer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,CFG.batch_size,shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset,CFG.batch_size,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Up(\n",
       "  (conv_up1): Conv_up_block(\n",
       "    (up_sample): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_up2): Conv_up_block(\n",
       "    (up_sample): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_up3): Conv_up_block(\n",
       "    (up_sample): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_up4): Conv_up_block(\n",
       "    (up_sample): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "from tqdm import tqdm\n",
    "device = 'cuda'\n",
    "unet = Unet().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(unet.parameters(),lr=1e-4)\n",
    "\n",
    "for epoch in tqdm(range(CFG.epoch)):\n",
    "    running_loss = 0.0\n",
    "    unet.train()\n",
    "    for i, (inputs,labels) in enumerate(train_dataloader):\n",
    "        inputs,labels = inputs.to(device).type(torch.float),labels.to(device).type(torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = unet(inputs)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'loss : {running_loss}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0 \n",
    "        for inputs,labels in test_dataloader:\n",
    "            inputs,labels = inputs.to(device).type(torch.float),labels.to(device).type(torch.float)\n",
    "            \n",
    "\n",
    "            outputs = unet(inputs)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            valid_loss += loss.item() \n",
    "\n",
    "        print(f'valid_loss : {valid_loss}')\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
